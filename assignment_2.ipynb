{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Github Link: https://github.com/Rezela/Natural-Language-Processing-2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Probabilistic Models and Vector Space Applications\n",
    "\n",
    "### Assignment Overview\n",
    "\n",
    "This assignment builds on fundamental text processing techniques to explore probabilistic language modeling, text classification, and the practical application of vector space models for information retrieval. You will implement a simple n-gram language model, build a complete text classification pipeline, develop a search engine, and analyze the core components of sequence models.\n",
    "\n",
    "You are required to complete five coding-related tasks. For each task, you will be working with a specified dataset or corpus. Please submit your solutions in this single Jupyter Notebook (`.ipynb`) file, clearly marking each task. Ensure your code is well-commented and your findings are explained in markdown cells where requested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Implementing a Bigram Language Model with Laplace Smoothing (20 Marks)\n",
    "\n",
    "**Objective:** To understand the fundamentals of n-gram language models, including probability calculation, smoothing, and evaluation with perplexity.\n",
    "\n",
    "**Description:** You will implement a Bigram language model from scratch. Your model will be trained on a small corpus and will use Add-One (Laplace) smoothing to handle unseen n-grams.\n",
    "\n",
    "**Your task is to:**\n",
    "\n",
    "1.  **Implement a training function `train_bigram_model(corpus)`:**\n",
    "    * The corpus will be a list of sentences, where each sentence is a list of tokens.\n",
    "    * The function should count all unigrams and bigrams in the corpus.\n",
    "    * It should return the unigram counts, bigram counts, and the vocabulary size (V).\n",
    "\n",
    "2.  **Implement a probability function `calculate_bigram_prob(prev_word, word, unigram_counts, bigram_counts, V)`:**\n",
    "    * This function should calculate the smoothed probability of a `word` given the `prev_word` using the formula for Laplace (Add-One) smoothing: $P(w_i | w_{i-1}) = \\frac{C(w_{i-1}, w_i) + 1}{C(w_{i-1}) + V}$.\n",
    "\n",
    "3.  **Implement a perplexity calculation function `calculate_perplexity(sentence, ...)`:**\n",
    "    * This function should take a test sentence and your trained model components as input.\n",
    "    * It should calculate the perplexity of the sentence using the formula: $PP(W) = P(w_1, w_2, ..., w_N)^{-1/N}$. Remember to handle the start of the sentence appropriately (e.g., by assuming a start token `<S>`).\n",
    "\n",
    "4.  **Train and Evaluate:**\n",
    "    * Train your model on the provided `train_corpus`.\n",
    "    * Calculate and print the perplexity of your model on the `test_sentence`.\n",
    "\n",
    "**Corpus:**\n",
    "\n",
    "```python\n",
    "# Sample corpus for training and testing\n",
    "train_corpus = [[\"<S>\", \"i\", \"am\", \"sam\", \"</S>\"], [\"<S>\", \"sam\", \"i\", \"am\", \"</S>\"], [\"<S>\", \"i\", \"do\", \"not\", \"like\", \"green\", \"eggs\", \"and\", \"ham\", \"</S>\"]]\n",
    "test_sentence = [\"<S>\", \"i\", \"like\", \"green\", \"ham\", \"</S>\"]\n",
    "```"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:44:46.089492Z",
     "start_time": "2025-11-02T14:44:46.012648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import urllib.request\n",
    "\n",
    "# Your code for Task 1 here\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Provided Corpus\n",
    "train_corpus = [[\"<S>\", \"i\", \"am\", \"sam\", \"</S>\"], [\"<S>\", \"sam\", \"i\", \"am\", \"</S>\"], [\"<S>\", \"i\", \"do\", \"not\", \"like\", \"green\", \"eggs\", \"and\", \"ham\", \"</S>\"]]\n",
    "test_sentence = [\"<S>\", \"i\", \"like\", \"green\", \"ham\", \"</S>\"]\n",
    "\n",
    "def train_bigram_model(corpus):\n",
    "    unigram_counts = Counter()  # 计数器\n",
    "    bigram_counts = Counter()\n",
    "    vocab = set()  # Vocabulary set集合 自动去重\n",
    "\n",
    "    for sentence in corpus:\n",
    "        for i in range(len(sentence)):\n",
    "            unigram_counts[sentence[i]]+=1\n",
    "            vocab.add(sentence[i])\n",
    "            # if not first word -> bigram\n",
    "            if i > 0:\n",
    "                bigram = (sentence[i-1], sentence[i])\n",
    "                bigram_counts[bigram] += 1\n",
    "    vocab_size = len(vocab)\n",
    "    return unigram_counts, bigram_counts, vocab_size\n",
    "\n",
    "# Calculate smoothed probability for one bigram(given 1 prev_word and 1 current word)\n",
    "def calculate_bigram_prob(prev_word, word, unigram_counts, bigram_counts, V):\n",
    "    # Implement smoothed probability calculation\n",
    "    bigram = (prev_word, word)\n",
    "    bigram_count = bigram_counts[bigram]\n",
    "    unigram_count = unigram_counts[prev_word]\n",
    "    # Laplace (Add-One) smoothing\n",
    "    prob = (bigram_count + 1) / (unigram_count + V)\n",
    "    return prob\n",
    "\n",
    "def calculate_perplexity(sentence, unigram_counts, bigram_counts, V):\n",
    "    # Implement perplexity calculation\n",
    "    '''\n",
    "    first: logPP(W) = (-1/N)*sum(log(p(w i|w i-1)))\n",
    "    then: PP(W) = exp(logPP(w))\n",
    "    '''\n",
    "    N = len(sentence) - 1\n",
    "    sum_prob = 0\n",
    "    for i in range(N):\n",
    "        bigram = (sentence[i],sentence[i+1])\n",
    "        bigram_prob = calculate_bigram_prob(bigram[0], bigram[1], unigram_counts, bigram_counts, V)\n",
    "        sum_prob += np.log(bigram_prob)\n",
    "    perplexity = np.exp(-sum_prob/N)\n",
    "    return perplexity\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Train the model\n",
    "    unigram_counts, bigram_counts, V = train_bigram_model(train_corpus)\n",
    "\n",
    "    # Calculate and print perplexity\n",
    "    perplexity = calculate_perplexity(test_sentence, unigram_counts, bigram_counts, V)\n",
    "    print(f\"Perplexity of the test sentence: {perplexity:.2f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of the test sentence: 8.37\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 1 Result:\n",
    "\n",
    "Perplexity of the test sentence: **8.37**。\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 2: Text Classification with TF-IDF and Naive Bayes (20 Marks)\n",
    "\n",
    "**Objective:** To build a complete text classification pipeline using TF-IDF feature extraction and a Multinomial Naive Bayes classifier.\n",
    "\n",
    "**Description:** You will use `scikit-learn` to classify SMS messages as either \"spam\" or \"ham\" (not spam). This task integrates vector space representation with a classic probabilistic model.\n",
    "\n",
    "**Your task is to:**\n",
    "\n",
    "1.  Load the SMS Spam Collection dataset.\n",
    "2.  Split the dataset into an 80% training set and a 20% testing set.\n",
    "3.  Create a text processing pipeline using `sklearn.pipeline.Pipeline` that consists of two steps:\n",
    "    * `TfidfVectorizer`: To convert text messages into TF-IDF vectors. Use the default parameters.\n",
    "    * `MultinomialNB`: The Multinomial Naive Bayes classifier.\n",
    "4.  Train the pipeline on the training data.\n",
    "5.  Evaluate the trained model on the testing data. Print the following:\n",
    "    * The accuracy of the model.\n",
    "    * A full classification report (including precision, recall, and F1-score for each class) using `sklearn.metrics.classification_report`.\n",
    "6.  Use the trained pipeline to predict the class of two new messages: `\"Congratulations! You've won a $1,000 gift card. Go to http://example.com to claim now.\"` and `\"Hi mom, I'll be home for dinner tonight.\"`\n",
    "\n",
    "**Dataset:**\n",
    "\n",
    "* **SMS Spam Collection Dataset:** A public set of SMS labeled messages.\n",
    "* **Access:** Download from the UCI Machine Learning Repository: [SMS Spam Collection](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). You will need the `SMSSpamCollection` file."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T12:25:27.803106Z",
     "start_time": "2025-11-01T12:25:27.642359Z"
    }
   },
   "source": [
    "# Your code for Task 2 here\n",
    "import os\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset, e.g, as follows. But you may modify it.\n",
    "# df = pd.read_csv('path_to_your_dataset/SMSSpamCollection', sep='\\t', header=None, names=['label', 'message'])\n",
    "\n",
    "# download dataset\n",
    "dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
    "dataset_zip = \"smsspamcollection.zip\"\n",
    "dataset_file = \"SMSSpamCollection\"\n",
    "\n",
    "if not os.path.exists(dataset_file):\n",
    "    print(\"Downloading dataset...\")\n",
    "    # download\n",
    "    urllib.request.urlretrieve(dataset_url, dataset_zip)\n",
    "    # unzip\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\".\")  # unzip to current directory\n",
    "    print(\"Dataset downloaded and extracted.\")\n",
    "\n",
    "# Load the dataset, Tab(\"\\t\") as separator, without a line of header, column 1: label, column 2: message\n",
    "df = pd.read_csv(dataset_file, sep=\"\\t\", header=None, names=[\"label\", \"message\"])\n",
    "print(\"Dataset loaded. Shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# Split data\n",
    "x = df[\"message\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# set a random seed: 28, stratify=y to make sure test size has same proportion of each class as the whole dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=28, stratify=y\n",
    ")\n",
    "\n",
    "# Create and train the pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"nb\", MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Predict on new messages\n",
    "new_messages = [\n",
    "    \"Congratulations! You've won a $1,000 gift card. Go to http://example.com to claim now.\",\n",
    "    \"Hi mom, I'll be home for dinner tonight.\"\n",
    "]\n",
    "predictions = pipeline.predict(new_messages)\n",
    "for message, prediction in zip(new_messages, predictions):  # 两个列表并行配对遍历\n",
    "    print(f\"Message: {message}\\nPrediction: {prediction}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Shape: (5572, 2)\n",
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "Accuracy:  0.9623318385650225\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       966\n",
      "        spam       1.00      0.72      0.84       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.86      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n",
      "Message: Congratulations! You've won a $1,000 gift card. Go to http://example.com to claim now.\n",
      "Prediction: spam\n",
      "\n",
      "Message: Hi mom, I'll be home for dinner tonight.\n",
      "Prediction: ham\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 2 Result\n",
    "### Dataset\n",
    "Loaded dataset shape: **(5572, 2)**\n",
    "\n",
    "| label | message |\n",
    "|-------|---------|\n",
    "| ham   | Go until jurong point, crazy.. Available only ... |\n",
    "| ham   | Ok lar... Joking wif u oni... |\n",
    "| spam  | Free entry in 2 a wkly comp to win FA Cup fina... |\n",
    "| ham   | U dun say so early hor... U c already then say... |\n",
    "| ham   | Nah I don't think he goes to usf, he lives aro... |\n",
    "\n",
    "---\n",
    "\n",
    "### Model Performance\n",
    "**Accuracy:** `0.9623`\n",
    "\n",
    "#### Classification Report\n",
    "\n",
    "| Class | Precision | Recall | F1-score | Support |\n",
    "|-------|-----------|--------|----------|---------|\n",
    "| ham   | 0.96      | 1.00   | 0.98     | 966     |\n",
    "| spam  | 1.00      | 0.72   | 0.84     | 149     |\n",
    "| **Accuracy** |       |        | **0.96** | 1115    |\n",
    "| **Macro avg** | 0.98 | 0.86   | 0.91     | 1115    |\n",
    "| **Weighted avg** | 0.96 | 0.96 | 0.96     | 1115    |\n",
    "\n",
    "---\n",
    "\n",
    "### Predictions on New Messages\n",
    "`\"Congratulations! You've won a $1,000 gift card. Go to http://example.com to claim now.\"` : **spam**\n",
    "\n",
    "`\"Hi mom, I'll be home for dinner tonight.\"` : **ham**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Building a Simple Information Retrieval System (20 Marks)\n",
    "\n",
    "**Objective:** To apply TF-IDF and Cosine Similarity to build a basic document retrieval system that ranks documents based on their relevance to a query.\n",
    "\n",
    "**Description:** You will create a system that takes a text query and returns the most relevant documents from a small corpus. This is the core principle behind search engines.\n",
    "\n",
    "**Your task is to:**\n",
    "\n",
    "1.  Use the provided `document_corpus`.\n",
    "2.  Create a `TfidfVectorizer` and fit it on the corpus to learn the vocabulary and IDF weights.\n",
    "3.  Transform the corpus into a TF-IDF document-term matrix.\n",
    "4.  Write a function `rank_documents(query, vectorizer, doc_term_matrix, top_n=3)` that:\n",
    "    * Takes a `query` string, the fitted `vectorizer`, the document-term `matrix`, and an optional `top_n` integer.\n",
    "    * Transforms the input query into a TF-IDF vector using the *same* vectorizer.\n",
    "    * Calculates the cosine similarity between the query vector and all document vectors in the matrix.\n",
    "    * Returns the indices and content of the `top_n` most similar documents.\n",
    "5.  Demonstrate your system by running it with the query `\"deep learning models for vision\"` and printing the ranked results.\n",
    "\n",
    "**Dataset:**\n",
    "\n",
    "```python\n",
    "# A small corpus of document abstracts\n",
    "document_corpus = [\n",
    "    \"The field of machine learning has seen rapid growth in recent years, especially in deep learning.\",\n",
    "    \"Natural language processing allows machines to understand and respond to human text.\",\n",
    "    \"Computer vision focuses on enabling computers to see and interpret the visual world.\",\n",
    "    \"Deep learning models like convolutional neural networks are powerful for computer vision tasks.\",\n",
    "    \"Recurrent neural networks are often used for sequential data in natural language processing.\"\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T19:14:55.554551Z",
     "start_time": "2025-11-01T19:14:55.547718Z"
    }
   },
   "source": [
    "# Your code for Task 3 here\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "document_corpus = [\n",
    "    \"The field of machine learning has seen rapid growth in recent years, especially in deep learning.\",\n",
    "    \"Natural language processing allows machines to understand and respond to human text.\",\n",
    "    \"Computer vision focuses on enabling computers to see and interpret the visual world.\",\n",
    "    \"Deep learning models like convolutional neural networks are powerful for computer vision tasks.\",\n",
    "    \"Recurrent neural networks are often used for sequential data in natural language processing.\",\n",
    "    \"The advances in reinforcement learning have led to breakthroughs in game playing and robotics.\",\n",
    "    \"Transfer learning enables models trained on large datasets to be adapted for new tasks with limited data.\",\n",
    "    \"Unsupervised learning techniques can discover hidden patterns in data without labeled examples.\",\n",
    "    \"Optimization algorithms such as stochastic gradient descent are crucial for training neural networks.\",\n",
    "    \"Attention mechanisms have improved the performance of natural language translation and image captioning.\",\n",
    "    \"Generative adversarial networks create realistic images and are used for data augmentation.\",\n",
    "    \"Feature engineering and selection are important steps in classical machine learning pipelines.\",\n",
    "    \"Object detection is a key task in computer vision that involves locating instances within images.\",\n",
    "    \"The combination of convolutional and recurrent networks is used for video classification tasks.\",\n",
    "    \"Zero-shot learning allows models to recognize objects and concepts they have not seen during training.\",\n",
    "    \"Natural language generation is used for creating text summaries and chatbot responses.\",\n",
    "    \"Graph neural networks leverage graph structures for tasks such as social network analysis and chemistry.\",\n",
    "    \"Hyperparameter tuning can significantly improve the accuracy of deep learning models.\",\n",
    "    \"Cross-modal learning involves integrating information from multiple data sources such as text and images.\",\n",
    "    \"Evaluating model performance requires a good choice of metrics such as F1-score and RMSE.\"\n",
    "]\n",
    "\n",
    "# Create and fit the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transform the corpus to DTM\n",
    "doc_term_matrix = vectorizer.fit_transform(document_corpus)\n",
    "\n",
    "def rank_documents(query, vectorizer, doc_term_matrix, top_n=3):\n",
    "    vec_query = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(vec_query, doc_term_matrix).flatten()\n",
    "\n",
    "    # Get indices of top_n documents, sorted by similarity\n",
    "    top_indices = similarities.argsort()[::-1][:top_n]\n",
    "\n",
    "    results = []\n",
    "    for rank, index in enumerate(top_indices, start=1):\n",
    "        results.append((rank, index, document_corpus[index], similarities[index]))\n",
    "    return results\n",
    "\n",
    "# Demonstrate with a sample query\n",
    "query = \"deep learning models for vision\"\n",
    "ranked_docs = rank_documents(query, vectorizer, doc_term_matrix, top_n=3)\n",
    "print(f\"Top {len(ranked_docs)} documents for the query: '{query}'\\n\")\n",
    "for rank, index, document, similarity in ranked_docs:\n",
    "    print(f\"Rank {rank}: (the {index}th document) {document} | Score = {similarity:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 documents for the query: 'deep learning models for vision'\n",
      "\n",
      "Rank 1: (the 3th document) Deep learning models like convolutional neural networks are powerful for computer vision tasks. | Score = 0.5550\n",
      "Rank 2: (the 17th document) Hyperparameter tuning can significantly improve the accuracy of deep learning models. | Score = 0.3276\n",
      "Rank 3: (the 0th document) The field of machine learning has seen rapid growth in recent years, especially in deep learning. | Score = 0.2139\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 3 Result\n",
    "Top 3 Documents for the Query: *\"deep learning models for vision\"*\n",
    "\n",
    "| Rank | Document Index | Content                                                                 | Score  |\n",
    "|------|----------------|-------------------------------------------------------------------------|--------|\n",
    "| 1    | 3              | Deep learning models like convolutional neural networks are powerful for computer vision tasks. | 0.5550 |\n",
    "| 2    | 17             | Hyperparameter tuning can significantly improve the accuracy of deep learning models. | 0.3276 |\n",
    "| 3    | 0              | The field of machine learning has seen rapid growth in recent years, especially in deep learning. | 0.2139 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Implementing Viterbi for HMM POS Tagging (20 Marks)\n",
    "\n",
    "**Objective:** Implement a simple Hidden Markov Model (HMM) POS tagger via the Viterbi algorithm.\n",
    "\n",
    "**Description:** Implement Viterbi decoding for a small HMM and apply it to two sentences with the ambiguous word \"book\". Then briefly discuss why HMMs work for POS tagging and a limitation of the Markov assumption.\n",
    "\n",
    "**Your task is to:**\n",
    "\n",
    "1. Define two sentences:\n",
    "    * `sentence1 = \"The book is on the table.\"`\n",
    "    * `sentence2 = \"I want to book a flight.\"`\n",
    "2. Implement Viterbi in log-space for a small tag set (e.g., `{DET, NOUN, VERB, PRT}`). Use the example initial (π), transition (A), and emission (B) probabilities in the parameters block below, or define your own consistent matrices and document them.\n",
    "3. Run your decoder on both sentences and print the predicted tag sequence and total log-probability.\n",
    "4. In a markdown cell, explain:\n",
    "    * **a)** How transition and emission probabilities lead to different tags for \"book\" in the two sentences.\n",
    "    * **b)** One sentence where the first-order Markov assumption is limiting, and why.\n",
    "\n",
    "**Parameters:** Use the matrices shown in the section “Viterbi decoding for a simple HMM (Task 4)” below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viterbi decoding for a simple HMM (Task 4)\n",
    "\n",
    "We illustrate HMM POS tagging with a small tag set `T = {DET, NOUN, VERB, PRT}` and vocabulary `V = {the, a, book, table, flight, is, want, to, on, i}`. The HMM comprises initial probabilities π, tag-to-tag transitions A, and tag-to-word emissions B.\n",
    "\n",
    "Example parameters (each row sums to 1):\n",
    "\n",
    "- Initial π:\n",
    "  - P(DET)=0.50, P(NOUN)=0.20, P(VERB)=0.20, P(PRT)=0.10\n",
    "\n",
    "- Transition A (rows: from-tag, cols: to-tag) in order [DET, NOUN, VERB, PRT]:\n",
    "\n",
    "```text\n",
    "from\\to   DET    NOUN   VERB   PRT\n",
    "DET      0.05   0.75   0.15   0.05\n",
    "NOUN     0.05   0.10   0.75   0.10\n",
    "VERB     0.10   0.35   0.40   0.15\n",
    "PRT      0.05   0.10   0.75   0.10\n",
    "```\n",
    "\n",
    "- Emission B:\n",
    "  - DET: the(0.80), a(0.20)\n",
    "  - NOUN: book(0.45), table(0.25), flight(0.20), i(0.05), on(0.05)\n",
    "  - VERB: is(0.40), want(0.35), book(0.20), to(0.03), on(0.02)\n",
    "  - PRT: to(0.70), on(0.30)\n",
    "\n",
    "Viterbi recurrence in log-space to avoid underflow:\n",
    "\n",
    "- Initialization: `V[tag, 0] = log π[tag] + log B[tag, x0]`\n",
    "- Recurrence: `V[tag, i] = log B[tag, xi] + max_prev ( V[prev, i-1] + log A[prev->tag] )`\n",
    "- Backtrace from the best final tag.\n",
    "\n",
    "We will decode the most likely tag sequence for the two Task 4 sentences using these parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:01:24.469778Z",
     "start_time": "2025-11-02T14:01:24.458923Z"
    }
   },
   "source": [
    "# Task 4: Implement Viterbi for a simple POS HMM (skeleton)\n",
    "import math\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Define your tag set\n",
    "TAGS = [\"DET\", \"NOUN\", \"VERB\", \"PRT\"]\n",
    "\n",
    "# Define HMM parameters (fill using the given parameters)\n",
    "pi: Dict[str, float] = {\n",
    "    \"DET\": 0.50,\n",
    "    \"NOUN\": 0.20,\n",
    "    \"VERB\": 0.20,\n",
    "    \"PRT\": 0.10\n",
    "}\n",
    "\n",
    "A: Dict[str, Dict[str, float]] = {\n",
    "    \"DET\":  {\"DET\": 0.05, \"NOUN\": 0.75, \"VERB\": 0.15, \"PRT\": 0.05},\n",
    "    \"NOUN\": {\"DET\": 0.05, \"NOUN\": 0.10, \"VERB\": 0.75, \"PRT\": 0.10},\n",
    "    \"VERB\": {\"DET\": 0.10, \"NOUN\": 0.35, \"VERB\": 0.40, \"PRT\": 0.15},\n",
    "    \"PRT\":  {\"DET\": 0.05, \"NOUN\": 0.10, \"VERB\": 0.75, \"PRT\": 0.10}\n",
    "}\n",
    "\n",
    "B: Dict[str, Dict[str, float]] = {\n",
    "    \"DET\":  {\"the\": 0.80, \"a\": 0.20},\n",
    "    \"NOUN\": {\"book\": 0.45, \"table\": 0.25, \"flight\": 0.20, \"i\": 0.05, \"on\": 0.05},\n",
    "    \"VERB\": {\"is\": 0.40, \"want\": 0.35, \"book\": 0.20, \"to\": 0.03, \"on\": 0.02},\n",
    "    \"PRT\":  {\"to\": 0.70, \"on\": 0.30}\n",
    "}\n",
    "\n",
    "UNK = 1e-8\n",
    "\n",
    "# Return log-probability for emitting 'word' from 'tag'. Use UNK for unseen words.\n",
    "def emission_logprob(tag: str, word: str) -> float:\n",
    "    prob = B.get(tag, {}).get(word, UNK)\n",
    "    return math.log(prob)\n",
    "\n",
    "# Implement Viterbi in log-space\n",
    "# 1) initialize  2) dynamic programming with backpointers  3) termination + backtrace\n",
    "def viterbi(tokens: List[str]) -> Tuple[List[str], float]:\n",
    "    n = len(tokens)\n",
    "    V = [{} for _ in range(n)]   # DP table\n",
    "    backpointer = [{} for _ in range(n)]\n",
    "\n",
    "    # Initialization\n",
    "    for tag in TAGS:\n",
    "        if pi[tag] > 0:\n",
    "            V[0][tag] = math.log(pi[tag]) + emission_logprob(tag, tokens[0])\n",
    "        else:\n",
    "            V[0][tag] = -math.inf\n",
    "        backpointer[0][tag] = None\n",
    "\n",
    "    # Recurrence\n",
    "    for i in range(1, n):\n",
    "        for tag in TAGS:\n",
    "            max_prob, best_prev = -math.inf, None\n",
    "            for prev in TAGS:\n",
    "                if V[i-1][prev] == -math.inf:\n",
    "                    continue\n",
    "                prob = V[i-1][prev] + math.log(A[prev][tag]) + emission_logprob(tag, tokens[i])\n",
    "                if prob > max_prob:\n",
    "                    max_prob, best_prev = prob, prev\n",
    "            V[i][tag] = max_prob\n",
    "            backpointer[i][tag] = best_prev\n",
    "\n",
    "    # Termination\n",
    "    final_tag = max(V[n-1], key=V[n-1].get)\n",
    "    best_logprob = V[n-1][final_tag]\n",
    "\n",
    "    # Backtrace\n",
    "    tags = [final_tag]\n",
    "    for i in range(n-1, 0, -1):\n",
    "        tags.insert(0, backpointer[i][tags[0]])\n",
    "\n",
    "    return tags, best_logprob\n",
    "\n",
    "# Prepare the two sentences (lowercased tokens)\n",
    "sentence1 = [\"the\", \"book\", \"is\", \"on\", \"the\", \"table\"]\n",
    "sentence2 = [\"i\", \"want\", \"to\", \"book\", \"a\", \"flight\"]\n",
    "\n",
    "# Run your decoder and print outputs\n",
    "tags1, logp1 = viterbi(sentence1)\n",
    "print(list(zip(sentence1, tags1)), \" | logP=\", round(logp1, 3))\n",
    "tags2, logp2 = viterbi(sentence2)\n",
    "print(list(zip(sentence2, tags2)), \" | logP=\", round(logp2, 3))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DET'), ('book', 'NOUN'), ('is', 'VERB'), ('on', 'PRT'), ('the', 'DET'), ('table', 'NOUN')]  | logP= -11.2\n",
      "[('i', 'NOUN'), ('want', 'VERB'), ('to', 'PRT'), ('book', 'VERB'), ('a', 'DET'), ('flight', 'NOUN')]  | logP= -15.903\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 4 Result\n",
    "#### Sentence 1: *\"The book is on the table.\"*\n",
    "| Word   | Tag  |\n",
    "|--------|------|\n",
    "| the    | DET  |\n",
    "| book   | NOUN |\n",
    "| is     | VERB |\n",
    "| on     | PRT  |\n",
    "| the    | DET  |\n",
    "| table  | NOUN |\n",
    "\n",
    "**Total log-probability:** `-11.2`\n",
    "\n",
    "---\n",
    "\n",
    "#### Sentence 2: *\"I want to book a flight.\"*\n",
    "| Word   | Tag  |\n",
    "|--------|------|\n",
    "| i      | NOUN |\n",
    "| want   | VERB |\n",
    "| to     | PRT  |\n",
    "| book   | VERB |\n",
    "| a      | DET  |\n",
    "| flight | NOUN |\n",
    "\n",
    "**Total log-probability:** `-15.903`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis for Task 4**\n",
    "\n",
    "* How transition and emission probabilities lead to different tags for \"book\" in the two sentences.\n",
    "\n",
    "\n",
    "* One sentence where the first-order Markov assumption is limiting, and why.\n",
    "\n",
    "In sentence 1: 'book' follows 'the', which is a DET. Tansition probility from 'DET' to 'NOUN' is 0.75, much higher than other cases. Emission probability P(book|none) is 0.45, also quite high.As a result, Viterbi decoding will choose 'NOUN' for 'book'.\n",
    "\n",
    "In sentence 2:'book' follows 'to', which is a PRT. Tansition probility from 'PRT' to 'VERB' is high of 0.75. Emission probability P(book|verb) is 0.20, also kind of reasonable. As a result, Viterbi decoding will choose 'VERB' for 'book'.\n",
    "\n",
    "Example sentence: **\"The old man the boats.\"**\n",
    "In this sentence, 'The old' means the old people, 'man' is a VERB representing manage. However, if the model of first-order Markov only consider one word above of 'old', it would consider 'old' as a ADJ, then predict 'man' as a NOUN. However, if taking the whole context into account, 'man' should be a VERB.\n",
    "To sum up, the example shows that the model of first-order Markov is not enough to capture the long context and dependence between words. So the model may make mistakes when encountering long ambiguous context and complex dependencies. In a more comprehensive task, models like LSTM or Transformer can be used to capture long-term dependencies and context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Comparing Cosine Similarity and Euclidean Distance (20 Marks)\n",
    "\n",
    "**Objective:** To empirically demonstrate the difference between angle-based (Cosine) and magnitude-based (Euclidean) similarity measures in a vector space.\n",
    "\n",
    "**Description:** The choice of similarity metric is crucial. This task highlights how document length affects each metric and why Cosine Similarity is often preferred for text-based topic similarity.\n",
    "\n",
    "**Your task is to:**\n",
    "\n",
    "1.  Define three simple documents:\n",
    "    * `doc_A = \"The cat sat on the mat.\"`\n",
    "    * `doc_B = \"The cat sat on the mat. The dog chased the cat.\"` (Longer, but on the same topic)\n",
    "    * `doc_C = \"The rocket launched into space.\"` (Different topic)\n",
    "2.  Use `sklearn.feature_extraction.text.CountVectorizer` to transform these three documents into count vectors.\n",
    "3.  Calculate the **Cosine Similarity** between all unique pairs of documents (A-B, A-C, B-C).\n",
    "4.  Calculate the **Euclidean Distance** between all unique pairs of documents.\n",
    "5.  Display your results clearly, for instance, in a Pandas DataFrame.\n",
    "6.  **In a markdown cell, analyze your results:**\n",
    "    * Explain why the Cosine Similarity between `doc_A` and `doc_B` is high, while their Euclidean Distance is relatively large.\n",
    "    * Which metric (Cosine Similarity or Euclidean Distance) do your results suggest is better for identifying documents with similar topics, regardless of their length? Justify your answer based on your calculations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:49:34.788710Z",
     "start_time": "2025-11-02T14:49:34.777657Z"
    }
   },
   "source": [
    "# Your code for Task 5 here\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import pandas as pd\n",
    "\n",
    "# Define documents\n",
    "doc_A = \"The cat sat on the mat.\"\n",
    "doc_B = \"The cat sat on the mat. The dog chased the cat.\"\n",
    "doc_C = \"The rocket launched into space.\"\n",
    "corpus = [doc_A, doc_B, doc_C]\n",
    "\n",
    "# Vectorize the documents\n",
    "vectorizer = CountVectorizer()\n",
    "text = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Calculate similarities and distances\n",
    "cos_sim = cosine_similarity(text)\n",
    "euclid_distance = euclidean_distances(text)\n",
    "\n",
    "# Display results in a DataFrame\n",
    "cos_df = pd.DataFrame(cos_sim, index=[\"doc_A\", \"doc_B\", \"doc_C\"], columns=[\"doc_A\", \"doc_B\", \"doc_C\"])\n",
    "euclid_df = pd.DataFrame(euclid_distance, index=[\"doc_A\", \"doc_B\", \"doc_C\"], columns=[\"doc_A\", \"doc_B\", \"doc_C\"])\n",
    "\n",
    "print(\"Cosine Similarity Matrix:\")\n",
    "print(cos_df)\n",
    "print(\"\\nEuclidean Distance Matrix:\")\n",
    "print(euclid_df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix:\n",
      "          doc_A     doc_B     doc_C\n",
      "doc_A  1.000000  0.919239  0.316228\n",
      "doc_B  0.919239  1.000000  0.357771\n",
      "doc_C  0.316228  0.357771  1.000000\n",
      "\n",
      "Euclidean Distance Matrix:\n",
      "          doc_A     doc_B     doc_C\n",
      "doc_A  0.000000  2.645751  3.000000\n",
      "doc_B  2.645751  0.000000  4.690416\n",
      "doc_C  3.000000  4.690416  0.000000\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 5 Result\n",
    "#### Cosine Similarity Matrix\n",
    "\n",
    "|       | doc_A   | doc_B   | doc_C   |\n",
    "|-------|---------|---------|---------|\n",
    "| **doc_A** | 1.000000 | 0.919239 | 0.316228 |\n",
    "| **doc_B** | 0.919239 | 1.000000 | 0.357771 |\n",
    "| **doc_C** | 0.316228 | 0.357771 | 1.000000 |\n",
    "\n",
    "---\n",
    "\n",
    "#### Euclidean Distance Matrix\n",
    "\n",
    "|       | doc_A   | doc_B   | doc_C   |\n",
    "|-------|---------|---------|---------|\n",
    "| **doc_A** | 0.000000 | 2.645751 | 3.000000 |\n",
    "| **doc_B** | 2.645751 | 0.000000 | 4.690416 |\n",
    "| **doc_C** | 3.000000 | 4.690416 | 0.000000 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis for Task 5**\n",
    "\n",
    "* Explain why the Cosine Similarity between `doc_A` and `doc_B` is high, while their Euclidean Distance is relatively large.\n",
    "\n",
    "* Which metric (Cosine Similarity or Euclidean Distance) do your results suggest is better for identifying documents with similar topics, regardless of their length? Justify your answer based on your calculations.\n",
    "\n",
    "Cosine Similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. It is often used to measure document similarity in text analysis.\n",
    "In this case, the Cosine Similarity between `doc_A` and `doc_B` is high of `0.919` because they share a lot of common words, such as \"the\", \"cat\", and \"on\". The similarity is high because the angle between the two vectors is small, which means they are similar in direction.\n",
    "\n",
    "Euclidean distance is a measure of the straight line distance between two points in Euclidean space. `doc_A` and `doc_B` Euclidean distance is large of `2.646` just because len(doc_B) is larger than len(doc_A), which makes the Euclidean distance larger.\n",
    "\n",
    "So as the result shows, **Cosine Similarity** is better for identifying documents with similar topics only focusing on the word distribution similarity, regardless of their length. Euclidean distance may misinterpret the length of the document as a factor, which may not be the case in many practical applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
